ğŸ“˜ INSTRUCTIONS.md fÃ¼r RooCode (MCP-Server)
ğŸ§  Ziel
Diese Anleitung beschreibt, wie du mit RooCode auf einem MCP-Server eine App erstellst, die:

Ã¼ber die OpenAI Assistants API auf einen Assistant mit Retrieval (Vector Store) zugreift,
eine grafische BenutzeroberflÃ¤che (GUI) mit Streamlit bietet,
den API-Key sicher aus einer .env-Datei liest,
Fragen an den Assistant sendet und Antworten anzeigt,
und sich fÃ¼r Investoren oder Nutzer einfach demonstrieren lÃ¤sst.

ğŸ“¦ Voraussetzungen
Python 3.10 oder hÃ¶her
OpenAI API-Key (in .env gespeichert)
Assistant mit Retrieval ist bereits bei OpenAI erstellt
RooCode-Umgebung mit Architekt, Coder, Debugger

ğŸ—‚ï¸ Projektstruktur
kirchenrecht_app/
â”œâ”€â”€ .env
â”œâ”€â”€ app.py
â”œâ”€â”€ assistant_setup.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ” .env â€“ API-Key speicher
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

ğŸ“¦ Requirements.txt - Pakete fÃ¼r die App
openai
streamlit
python-dotenv

ğŸ§± assistant_setup.py â€“ Assistant einmalig erstellen
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
client = OpenAI()

assistant = client.beta.assistants.create(
    name="EKHN Kirchenrecht Assistant",
    model="gpt-4o",
    instructions="Du bist ein Experte fÃ¼r das Kirchenrecht der EKHN. Antworte klar, kurz und mit Paragraphenangabe.",
    tools=[{"type": "retrieval"}]
)

print("Assistant ID:", assistant.id)
ğŸ’¡ Hinweis: Nur einmal ausfÃ¼hren. Die assistant.id notieren und in app.py verwenden.

ğŸ–¥ï¸ app.py â€“ Streamlit GUI
import streamlit as st
import time
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
client = OpenAI()

st.title("ğŸ•Šï¸ EKHN Kirchenrechts-Chat")

ASSISTANT_ID = "ASSISTANT_ID = "asst_er72T8D7D8xth2HaM0mjxi5m"
# Hier deine Assistant-ID einfÃ¼gen

question = st.text_input("Stelle deine Frage:")

if st.button("Frage stellen") and question:
    thread = client.beta.threads.create()
    client.beta.threads.messages.create(thread_id=thread.id, role="user", content=question)
    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=ASSISTANT_ID)

    with st.spinner("Antwort wird generiert..."):
        while run.status != "completed":
            time.sleep(0.5)
            run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)

        answer = client.beta.threads.messages.list(thread_id=thread.id).data[0].content[0].text.value
        st.success(answer)

ğŸš€ Starten
pip install -r requirements.txt
streamlit run app.py

ğŸ’° Kostenkontrolle
OpenAI Dashboard â†’ Usage â†’ â€Set usage limitâ€œ â†’ z.â€¯B. 5â€¯â‚¬
Im Code kannst du run.usage.total_tokens auslesen und eigene Limits setzen
ğŸ“¦ Deployment-Optionen
Option	Beschreibung
streamlit run app.py	Lokale Demo
pyinstaller app.py	.exe fÃ¼r Windows
streamlit.io oder VPS	Online-Zugang fÃ¼r Investoren

ğŸ§ª Testen der App


Beispiel-Frage:
> â€Darf eine Pfarrerin das Abendmahl ohne Ordination spenden?â€œ

Erwartete Antwort:
> Der Assistant sollte einen relevanten Paragraphen aus dem Kirchenrecht zitieren und eine kurze, klare BegrÃ¼ndung liefern.

## ğŸ§° Fehlerbehandlung

- Wenn keine Antwort erscheint: Stelle sicher, dass dein API-Key korrekt in `.env` gespeichert ist.
- Wenn `run.status` nicht `completed` wird: ÃœberprÃ¼fe deine Internetverbindung und API-Limits.
- Bei `InvalidRequestError`: PrÃ¼fe, ob der Assistant korrekt erstellt wurde und die ID stimmt.

## ğŸ” Sicherheit

- Gib deinen API-Key **niemals Ã¶ffentlich weiter**.
- Nutze `.env` und `python-dotenv`, um den Key aus dem Code herauszuhalten.
- Setze im OpenAI-Dashboard ein **Usage-Limit**, z.â€¯B. 5â€¯â‚¬ pro Monat.
